{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from https://github.com/hadrienj/deepLearningBook-Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we cover some basics of Linear Algebra as seen in [Deep Learning Book](http://www.deeplearningbook.org/contents/linear_algebra.html) with a focus on using numpy\n",
    "\n",
    "\n",
    "### 1. Scalars & Vectors\n",
    "\n",
    "* **Scalar** is a *single* number, denoted as $x$\n",
    "\n",
    "\n",
    "* **Vector** is an *array of scalars*, denoted by $\\boldsymbol{x}$\n",
    "    * Thus, a vector has $n$ scalars $x_1, x_2 \\cdots x_n$\n",
    "    * Note that indexing here begins with 1, unlike python (where it begins with 0)\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x} =\\begin{bmatrix}\n",
    "    x_1 \\\\\n",
    "    x_2 \\\\\n",
    "    \\cdots \\\\\n",
    "    x_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Let us now look how we can create an array using `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "x1 = np.array([[4, 5, 6]])\n",
    "print(x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      "[[4]\n",
      " [5]\n",
      " [8]]\n",
      "\n",
      "shape: (3, 1)\n",
      "x[2]: 8\n"
     ]
    }
   ],
   "source": [
    "# We will represent a vector as a column vector, that is having multiple rows\n",
    "x = np.array([[4], [5], [8]])\n",
    "print(f'x: \\n{x}\\n')\n",
    "\n",
    "print(f'shape: {x.shape}')\n",
    "\n",
    "print(f'x[2]: {x[2][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Matrices & Tensors\n",
    "\n",
    "* **Matrix** is a 2D array of scalars, denoted by $\\boldsymbol{X}$\n",
    "$$\n",
    "\\boldsymbol{X}=\n",
    "\\begin{bmatrix}\n",
    "    X_{1,1} & X_{1,2} & \\cdots & X_{1,n} \\\\\\\\\n",
    "    X_{2,1} & X_{2,2} & \\cdots & X_{2,n} \\\\\\\\\n",
    "    \\cdots & \\cdots & \\cdots & \\cdots \\\\\\\\\n",
    "    X_{m,1} & X_{m,2} & \\cdots & X_{m,n}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "    - This matrix has $m$ rows and $n$ columns\n",
    "    - Each indvidual element such as $X_{1,1}$ is a *scalar*\n",
    "    - If $m = n$, the matrix is known as **Square** Matrix\n",
    "\n",
    "\n",
    "* **Tensor** is an array with **more than 2** axes, denoted as **X**\n",
    "    * Think of Tensor as a generalization of an array with more than 2 axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: \n",
      "[[ 4  5  7]\n",
      " [10 11 13]\n",
      " [56 80 90]]\n",
      "\n",
      "shape: (3, 3)\n",
      "X[2][1]: 80\n"
     ]
    }
   ],
   "source": [
    "#Here X is a Matrix\n",
    "X = np.array([[4,5,7], [10, 11, 13], [56, 80, 90]])\n",
    "print(f'X: \\n{X}\\n')\n",
    "print(f'shape: {X.shape}')\n",
    "\n",
    "print(f'X[2][1]: {X[2][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 2, 3)\n",
      "T[1][0][1]: 80\n"
     ]
    }
   ],
   "source": [
    "#Here T is a Tensor\n",
    "T = np.array([[[4, 5, 7], [10, 11, 13]], [[56, 80, 90], [9, 8, 10]]])\n",
    "print(f'shape: {T.shape}')\n",
    "\n",
    "print(f'T[1][0][1]: {T[1][0][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Transpose\n",
    "For a 2D matrix transpose can be obtained as follows\n",
    "$(A^T)_{i,j} = A_{j, i}$\n",
    "\n",
    "For a vector, transpose makes the column vector into a row. Thus a column vector can also be represented as $\\boldsymbol{x} = [x_1, x_2, x_3]^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x transpose shape: (1, 3)\n",
      "Xt transpose shape: (3, 3)\n",
      "Tt transpose shape: (2, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "xt = np.transpose(x)\n",
    "print(f'x transpose shape: {xt.shape}')\n",
    "\n",
    "Xt = np.transpose(X)\n",
    "print(f'Xt transpose shape: {Xt.shape}')\n",
    "\n",
    "Tt = np.transpose(T, axes=[0, 2, 1])\n",
    "print(f'Tt transpose shape: {Tt.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Broadcasting\n",
    "\n",
    "* You can add a scalar to a vector, and numpy will add it to each element in the vector\n",
    "    \n",
    "    $\\boldsymbol{x} + a = \\boldsymbol{x}_i + a$\n",
    "    \n",
    "    \n",
    "* Similarly you can add a vector to a matrix, and numpy will add the vector to each column of the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      "[[4]\n",
      " [5]\n",
      " [8]]\n",
      "\n",
      "x+3: \n",
      "[[ 7]\n",
      " [ 8]\n",
      " [11]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'x: \\n{x}\\n')\n",
    "print(f'x+3: \\n{x + 3}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: \n",
      "[[ 4  5  7]\n",
      " [10 11 13]\n",
      " [56 80 90]]\n",
      "\n",
      "x: \n",
      "[[4]\n",
      " [5]\n",
      " [8]]\n",
      "\n",
      "X+x: \n",
      "[[ 8  9 11]\n",
      " [15 16 18]\n",
      " [64 88 98]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'X: \\n{X}\\n')\n",
    "print(f'x: \\n{x}\\n')\n",
    "print(f'X+x: \\n{X + x}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Matrix Multiplication\n",
    "\n",
    "This is perhaps one operation that you would use quite frequently in any ML/DL model.\n",
    "You should remember a few things about multiplication\n",
    "\n",
    "* $\\boldsymbol{C} = \\boldsymbol{A} \\boldsymbol{B}$ is only defined when the second dimension of $\\boldsymbol{A}$ matches the first dimension of $\\boldsymbol{B}$\n",
    "\n",
    "\n",
    "* Further, if  $\\boldsymbol{A}$ is of shape (m, n) and $\\boldsymbol{B}$ of shape (n, p), then $\\boldsymbol{C}$ is of shape (m, p) \n",
    "\n",
    "\n",
    "* This operation is concretely defined as $C_{i,j} = \\sum_k A_{i, k} B_{k, j}$\n",
    "\n",
    "    * $\\boldsymbol{C}_{i, j}$ is computed by taking the dot product of $i$-th row of $\\boldsymbol{A}$ with $j$-th column of $\\boldsymbol{B}$\n",
    "\n",
    "\n",
    "* A more useful method to think of matrix multiplcation is as **linear combination of columns** of $\\boldsymbol{A}$ weighted by column entries of $\\boldsymbol{B}$\n",
    "\n",
    "<img src=\"images/mat-mul2.png\" width=\"400\" alt=\"Matrix Multiplication\" title=\"Mat Mul\">\n",
    "\n",
    "\n",
    "<em>Matrix Multiplication. Image Credit: https://www.mpcm.org/visualizing-matrix-multiplication-as-a-linear-combination-eli-benderskys-website/</em>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: \n",
      "[[ 4  5  7]\n",
      " [10 11 13]\n",
      " [56 80 90]]\n",
      "\n",
      "x: \n",
      "[[4]\n",
      " [5]\n",
      " [8]]\n",
      "\n",
      "[[  97]\n",
      " [ 199]\n",
      " [1344]]\n"
     ]
    }
   ],
   "source": [
    "print(f'X: \\n{X}\\n')\n",
    "\n",
    "print(f'x: \\n{x}\\n')\n",
    "\n",
    "print(np.matmul(X, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Element Wise multiplication: Hadamard product\n",
    "\n",
    "Element wise multiplication $\\boldsymbol{A} \\odot \\boldsymbol{B}$\n",
    "\n",
    "Notice how numpy uses the * for this. Important to be careful, and not to confuse this with matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: \n",
      "[[ 4  5  7]\n",
      " [10 11 13]\n",
      " [56 80 90]]\n",
      "\n",
      "Y: \n",
      "[[ 40  50  70]\n",
      " [100 110 130]\n",
      " [560 800 900]]\n",
      "\n",
      "X * Y: \n",
      "[[  160   250   490]\n",
      " [ 1000  1210  1690]\n",
      " [31360 64000 81000]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Different from element wise multiplication\n",
    "\n",
    "Y = np.array([[40, 50, 70], [100, 110, 130], [560, 800, 900]])\n",
    "\n",
    "print(f'X: \\n{X}\\n')\n",
    "print(f'Y: \\n{Y}\\n')\n",
    "\n",
    "print(f'X * Y: \\n{X * Y}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Norms\n",
    "\n",
    "* Norm can be thought of as a proxy for size of a vector. \n",
    "\n",
    "  We define $L^p$ norm $\\Vert \\boldsymbol{x}\\Vert _p = (\\sum |\\boldsymbol{x}_i|^{p})^{\\frac{1}{p}}$ \n",
    "  \n",
    "  $p \\ge 1, p \\in \\Re$\n",
    "  \n",
    "  \n",
    "* Norm is a *function* that maps vectors to *non-negative* values. A norm satisfies the following properties:\n",
    "    * $f(\\boldsymbol{x}) = 0 =>  \\boldsymbol{x} = 0$\n",
    "    * $f(\\boldsymbol{x} + \\boldsymbol{y}) \\le f(\\boldsymbol{x}) + f(\\boldsymbol{y})$ (Triangle inequality)\n",
    "    * $\\forall \\ \\alpha \\in \\Re, \\ f(\\alpha \\ \\boldsymbol{x}) = |\\alpha|\\ f(\\boldsymbol{x})$\n",
    "  \n",
    "  \n",
    "* $L^2$ norm is called the **Euclidean norm**, often $\\Vert \\boldsymbol{x} \\Vert$ \n",
    "    * We work mostly with squared $L^2$ norm which can be computed as $\\boldsymbol{x}^T \\boldsymbol{x}$\n",
    "    \n",
    "    * Squared $L^2$ norm is easier to work with as its derivative is $2 * \\boldsymbol{x}$\n",
    "   \n",
    "    * In some ML applications it is important to distinguish between elements that are zero and small but zero. Squared $L^2$ norm may not be the right choice as it grows very slowly near the origin\n",
    "    \n",
    "    \n",
    "* **$L^1$ norm** is the absolute sum of all members of a vector\n",
    "\n",
    "    * Useful when difference between 0 and non-zero elements is essential.\n",
    "\n",
    "\n",
    "* **Max-Norm**: $L^\\infty$: This simplifies to absoute value of the element with highest magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      "[[4]\n",
      " [5]\n",
      " [8]]\n",
      "\n",
      "lp2 10.246950765959598\n",
      "lp1 17.0\n",
      "lp_inf 8.0\n"
     ]
    }
   ],
   "source": [
    "print(f'x: \\n{x}\\n')\n",
    "\n",
    "lp2 = np.linalg.norm(x)\n",
    "print(f'lp2 {lp2}')\n",
    "\n",
    "lp1 = np.linalg.norm(x, ord=1)\n",
    "print(f'lp1 {lp1}')\n",
    "\n",
    "lp_inf = np.linalg.norm(x, ord=np.inf)\n",
    "print(f'lp_inf {lp_inf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
